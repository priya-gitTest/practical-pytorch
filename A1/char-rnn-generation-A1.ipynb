{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "\n",
    "The file we are using is a plain text file. We turn any potential unicode characters into plain ASCII by using the `unidecode` package (which you can install via `pip` or `conda`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 7664627\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "n_characters = 2**16 # basic multilingual plane\n",
    "kPadCharIndex = n_characters\n",
    "kPadChar = chr(kPadCharIndex) # padding for batch\n",
    "kSOTChar = '\\u0002'\n",
    "kEOTChar = '\\u0003'\n",
    "n_characters += 1\n",
    "\n",
    "max_chunk_len = 40\n",
    "stride = 20\n",
    "\n",
    "json_fn = '../data/sentences_c%d_s%d.json' % (max_chunk_len, stride)\n",
    "if os.path.exists(json_fn):\n",
    "    with open(json_fn, 'r') as f:\n",
    "        dataset = json.load(f)\n",
    "        sentences, ords = dataset['sentences'], dataset['ords']\n",
    "else:\n",
    "    file = open('../data/sentences.csv').readlines()\n",
    "    sentences = []\n",
    "    for l in file:\n",
    "        assert(l[-1] == '\\n')\n",
    "        s = l.split('\\t')[-1][:-1]\n",
    "        o = [ord(c) for c in s]\n",
    "        if len(s) <= 0 or np.amax(o) >= n_characters -1:\n",
    "            continue\n",
    "        \n",
    "        s = kSOTChar + s + kEOTChar\n",
    "        if len(s) < max_chunk_len:\n",
    "            sentences.append(s)\n",
    "        else:\n",
    "            for i in range(0, len(s) - max_chunk_len + 1, stride):\n",
    "                sub_str = s[i:i+max_chunk_len]\n",
    "                sentences.append(sub_str)\n",
    "    sentences = sorted(sentences, key=len)\n",
    "    ords = [[ord(c) for c in s] for s in sentences]\n",
    "    with open(json_fn, 'w') as outfile:\n",
    "        json.dump({'sentences': sentences, 'ords': ords}, outfile)\n",
    "\n",
    "file_len = len(ords)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 40\n",
      "['\\x02네\\x03', '\\x02.\\x03', '\\x02錯。\\x03', '\\x02行。\\x03', '\\x02啥？\\x03', '\\x02滾。\\x03', '\\x02係。\\x03', '\\x02嘘！\\x03', '\\x02え？\\x03', '\\x02mo\\x03']\n",
      "['\\x02Vocês poderiam me ajudar a traduzir iss', '\\x02Posso usar o teu computador para olhar ', '\\x02The police recovered the stolen jewels.', '\\x02Do you think Tom will be in Boston all ', \"\\x02Let's just say that I wasn't surprised.\", \"\\x02Do you still think that's all Tom needs\", \"\\x02It won't be as easy to do as you think.\", '\\x02Do you know what Tom is going to do nex', '\\x02Do you mind if I lay down on the sofa?\\x03', '\\x02Ik verwachte Peter, maar het was zijn b']\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences[0]), len(sentences[-1]))\n",
    "print(sentences[:10])\n",
    "print(sentences[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make inputs out of this big string of data, we will be splitting it into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   69  107   32  119  105  108   32  110  105  101   32   97  108\n",
      "   108  101  101  110   32   98  108  121   32  110  105  101   46    3]\n",
      " [   2   78  111  110   32  118  111  114  114  101  105   32  114  105\n",
      "   109   97  110  101  114  101   32  115  101  110  122   97   33    3]\n",
      " [   2   83   99  117  115   97  116  101   44   32  110  111  110   32\n",
      "   104  111   32  114  101  115  105  115  116  105  116  111   33    3]\n",
      " [   2   69  107   32  119  105  108   32  106  117  108  108  101   32\n",
      "   110  105  101   32  115  105  101  110   32  110  105  101   46    3]\n",
      " [   2   77  225  114   32  115  111  107   32  104  101  108  121  101\n",
      "   110   32  109  101  103  102  111  114  100  117  108  116   46    3]\n",
      " [   2 1332 1400 1410 1412   32 1389 1400 1405 1400 1410 1374 1396   32\n",
      "  1381 1412   32 1414 1408 1377 1398 1405 1381 1408 1381 1398   58    3]\n",
      " [   2  199   97   98  117  107   32  111  108   33   32   89  101  109\n",
      "   101  107   32  115  111  287  117  121   97   99   97  107   46    3]\n",
      " [   2 1333 1405   32 1405 1408 1377   32 1396 1377 1405 1387 1398   32\n",
      "  1400 1401 1387 1398 1401   32 1401 1379 1387 1407 1381 1396   58    3]\n",
      " [   2  111  110   97   32  108  105   32  111  108  105  110   32  101\n",
      "    32  115  111  119  101  108  105   32   75   97  116  117   46    3]\n",
      " [   2   68  105  100  110   39  116   32  121  111  117   32  104  101\n",
      "    97  114   32  116  104  101   32   97  108   97  114  109   63    3]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# output size (seq_len, batch_size)\n",
    "def random_chunk():\n",
    "    index = random.randint(0, file_len-batch_size)\n",
    "    batch_s = ords[index: index + batch_size]\n",
    "    lens = [len(s) for s in batch_s]\n",
    "    max_len = np.amax(lens)\n",
    "    if (lens < max_len).any():\n",
    "        batch_s = [s + [kPadCharIndex,] * (max_len - len(s)) for s in batch_s]\n",
    "    return np.array(batch_s, dtype = int)\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Model\n",
    "\n",
    "This model will take as input the character for step $t_{-1}$ and is expected to output the next character $t$. There are three layers - one linear layer that encodes the input character into an internal state, one GRU layer (which may itself have multiple layers) that operates on that internal state and a hidden state, and a decoder layer that outputs the probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def cuda_if_available(v):\n",
    "    return v.cuda() if torch.cuda.is_available() else v\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, batch_first = True)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    # output:(batch, seq_len, out_size),\n",
    "    # hidden: (num_layers * num_directions, batch, hidden_size)\n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input) # (B, seq_len, embedding_dim)\n",
    "        output, hidden = self.gru(input, hidden) # output:(batch, seq_len, hidden_size * num_directions),\n",
    "        output = self.decoder(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        v = Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))\n",
    "        return cuda_if_available(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import set_trace as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs and Targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each chunk will be turned into a tensor, specifically a `LongTensor` (used for integer values), by looping through the characters of the string and looking up the index of each character in `all_characters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   78  111  116   32   97  110  111  116  104  101  114   32  119\n",
      "   111  114  100   33    3]\n",
      " [   2 1069 1090 1072   32 1088 1099 1073 1072   32 1074 1082 1091 1089\n",
      "  1085 1072 1103   46    3]\n",
      " [   2 1492 1500 1493 1493 1488 1497   32 1513 1492 1497 1497 1514 1497\n",
      "    32 1502 1514   46    3]\n",
      " [   2 2335 2377 2350   32 2358 2367 2357 2381 2351 2366   32 2342 2375\n",
      "  2340 2379 2351   46    3]\n",
      " [   2 1040 1074 1090 1086 1073 1091 1089   32 1087 1086 1076 1093 1086\n",
      "  1076 1080 1090   46    3]\n",
      " [   2   86  101  114  114  224   32   97  108  108   97   32  102  101\n",
      "   115  116   97   46    3]\n",
      " [   2 1069 1081   33   32 1054 1090 1087 1091 1089 1090 1080   32 1084\n",
      "  1077 1085 1103   33    3]\n",
      " [   2 1065 1077   32 1084 1080 1085 1072   32 1087 1086   45 1082 1098\n",
      "  1089 1085 1086   46    3]\n",
      " [   2 1065 1077   32 1073 1098 1076 1072   32 1085 1072 1082 1072 1079\n",
      "  1072 1085 1072   46    3]\n",
      " [   2  200   32  105  114  114  101   99  117  112  101  114   97   98\n",
      "   105  108  101   46    3]] Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    2    78   111   116    32    97   110   111   116   104   101   114    32\n",
      "    2  1069  1090  1072    32  1088  1099  1073  1072    32  1074  1082  1091\n",
      "    2  1492  1500  1493  1493  1488  1497    32  1513  1492  1497  1497  1514\n",
      "    2  2335  2377  2350    32  2358  2367  2357  2381  2351  2366    32  2342\n",
      "    2  1040  1074  1090  1086  1073  1091  1089    32  1087  1086  1076  1093\n",
      "    2    86   101   114   114   224    32    97   108   108    97    32   102\n",
      "    2  1069  1081    33    32  1054  1090  1087  1091  1089  1090  1080    32\n",
      "    2  1065  1077    32  1084  1080  1085  1072    32  1087  1086    45  1082\n",
      "    2  1065  1077    32  1073  1098  1076  1072    32  1085  1072  1082  1072\n",
      "    2   200    32   105   114   114   101    99   117   112   101   114    97\n",
      "\n",
      "Columns 13 to 18 \n",
      "  119   111   114   100    33     3\n",
      " 1089  1085  1072  1103    46     3\n",
      " 1497    32  1502  1514    46     3\n",
      " 2375  2340  2379  2351    46     3\n",
      " 1086  1076  1080  1090    46     3\n",
      "  101   115   116    97    46     3\n",
      " 1084  1077  1085  1103    33     3\n",
      " 1098  1089  1085  1086    46     3\n",
      " 1079  1072  1085  1072    46     3\n",
      "   98   105   108   101    46     3\n",
      "[torch.cuda.LongTensor of size 10x19 (GPU 0)]\n",
      "\n",
      "(Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    2  1057  1090  1088  1072  1074    32  1084  1080    32  1077    32  1076\n",
      "    2  1060  1086  1084  1072    32  1080    32  1052  1072  1096  1072    32\n",
      "    2  1060  1086  1084  1072    32  1080    32  1052  1072  1096  1072    32\n",
      "    2    83   105   107   108   243   118    97   108    32   109   101   103\n",
      "    2    73   111    32   110   111   110    32   108   111    32   114   105\n",
      "    2    73   111    32   110   111   110    32   108    97    32   114   105\n",
      "    2    66   101   110   105   109    32    98   101   108   108   105    32\n",
      "    2    66   101   108   107   105    32   100   101    32    84   111   109\n",
      "    2    65   107   115   105   108   105   107   108   101   114    32   104\n",
      "    2    84   111   109    44    32    77    97   114   121    39   121   101\n",
      "\n",
      "Columns 13 to 25 \n",
      " 1077  1082  1072    32  1058  1086  1084    32  1116  1077    32  1079  1072\n",
      " 1079  1072  1087  1083  1072  1090  1080  1083  1080    32  1087  1086  1087\n",
      " 1079  1072  1087  1083  1072  1090  1080  1083  1080    32  1087  1086  1088\n",
      "  121   252   110   107    32   102   101   108    32    97    32   104   101\n",
      "  101   115    99   111    32    97    32   100   105   109   111   115   116\n",
      "  101   115    99   111    32    97    32   100   105   109   111   115   116\n",
      "  115   116    97   110   100    97   114   116   108    97   114   305   109\n",
      "   39   108    97    32   107   111   110   117   351    97    98   105   108\n",
      "  101   112    32   252   115   116    32   252   115   116   101    32   103\n",
      "   32    98   105   114    97   122    32   112    97   114    97    32   118\n",
      "\n",
      "Columns 26 to 30 \n",
      " 1083  1091  1090  1072    46\n",
      " 1086  1083  1072  1084    46\n",
      " 1086  1074  1085  1091    46\n",
      "  103   121   114   101    46\n",
      "  114    97   114   101    46\n",
      "  114    97   114   101    46\n",
      "   32   118    97   114    46\n",
      "  105   114   105   122    46\n",
      "  101   108   105   114    46\n",
      "  101   114   100   105    46\n",
      "[torch.cuda.LongTensor of size 10x31 (GPU 0)]\n",
      ", Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      " 1057  1090  1088  1072  1074    32  1084  1080    32  1077    32  1076  1077\n",
      " 1060  1086  1084  1072    32  1080    32  1052  1072  1096  1072    32  1079\n",
      " 1060  1086  1084  1072    32  1080    32  1052  1072  1096  1072    32  1079\n",
      "   83   105   107   108   243   118    97   108    32   109   101   103   121\n",
      "   73   111    32   110   111   110    32   108   111    32   114   105   101\n",
      "   73   111    32   110   111   110    32   108    97    32   114   105   101\n",
      "   66   101   110   105   109    32    98   101   108   108   105    32   115\n",
      "   66   101   108   107   105    32   100   101    32    84   111   109    39\n",
      "   65   107   115   105   108   105   107   108   101   114    32   104   101\n",
      "   84   111   109    44    32    77    97   114   121    39   121   101    32\n",
      "\n",
      "Columns 13 to 25 \n",
      " 1082  1072    32  1058  1086  1084    32  1116  1077    32  1079  1072  1083\n",
      " 1072  1087  1083  1072  1090  1080  1083  1080    32  1087  1086  1087  1086\n",
      " 1072  1087  1083  1072  1090  1080  1083  1080    32  1087  1086  1088  1086\n",
      "  252   110   107    32   102   101   108    32    97    32   104   101   103\n",
      "  115    99   111    32    97    32   100   105   109   111   115   116   114\n",
      "  115    99   111    32    97    32   100   105   109   111   115   116   114\n",
      "  116    97   110   100    97   114   116   108    97   114   305   109    32\n",
      "  108    97    32   107   111   110   117   351    97    98   105   108   105\n",
      "  112    32   252   115   116    32   252   115   116   101    32   103   101\n",
      "   98   105   114    97   122    32   112    97   114    97    32   118   101\n",
      "\n",
      "Columns 26 to 30 \n",
      " 1091  1090  1072    46     3\n",
      " 1083  1072  1084    46     3\n",
      " 1074  1085  1091    46     3\n",
      "  121   114   101    46     3\n",
      "   97   114   101    46     3\n",
      "   97   114   101    46     3\n",
      "  118    97   114    46     3\n",
      "  114   105   122    46     3\n",
      "  108   105   114    46     3\n",
      "  114   100   105    46     3\n",
      "[torch.cuda.LongTensor of size 10x31 (GPU 0)]\n",
      ", Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "\n",
      "Columns 13 to 25 \n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "\n",
      "Columns 26 to 30 \n",
      "    1     1     1     1     1\n",
      "    1     1     1     1     1\n",
      "    1     1     1     1     1\n",
      "    1     1     1     1     1\n",
      "    1     1     1     1     1\n",
      "    1     1     1     1     1\n",
      "    1     1     1     1     1\n",
      "    1     1     1     1     1\n",
      "    1     1     1     1     1\n",
      "    1     1     1     1     1\n",
      "[torch.cuda.FloatTensor of size 10x31 (GPU 0)]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def cuda_if_available(v):\n",
    "    return v.cuda() if torch.cuda.is_available() else v\n",
    "\n",
    "\n",
    "# Turn string into list of longs\n",
    "def char_tensor(ords_batch):\n",
    "    tensor = torch.from_numpy(ords_batch).long()\n",
    "    v = Variable(tensor)\n",
    "    return cuda_if_available(v)\n",
    "\n",
    "# size: (B, seq_len)\n",
    "def random_training_set():\n",
    "    while True:\n",
    "        chunk = random_chunk()\n",
    "        if chunk.shape[1] > 1:\n",
    "            break\n",
    "    inp = char_tensor(chunk[:,:-1])\n",
    "    target = char_tensor(chunk[:,1:])\n",
    "    mask_np = (chunk[:,1:] != kPadCharIndex).astype(np.float32)\n",
    "    mask = Variable(torch.from_numpy(mask_np), requires_grad = False)\n",
    "    \n",
    "    return inp, target, cuda_if_available(mask)\n",
    "\n",
    "chunk = random_chunk()\n",
    "print(chunk, char_tensor(chunk))\n",
    "print(random_training_set())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can assemble a pair of input and target tensors for training, from a random chunk. The input will be all characters *up to the last*, and the target will be all characters *from the first*. So if our chunk is \"abc\" the input will correspond to \"ab\" while the target is \"bc\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating\n",
    "\n",
    "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden(1)\n",
    "    prime_str = kSOTChar + prime_str\n",
    "    prime_input = char_tensor(np.array([[ord(c) for c in prime_str]]))\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    _, hidden = decoder(prime_input[:,:-1], hidden)\n",
    "    inp = prime_input[:,-1].view(1,1)\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = chr(top_i)\n",
    "        predicted += predicted_char\n",
    "        \n",
    "        inp_np = np.array([[ord(predicted_char)]])\n",
    "        inp = char_tensor(inp_np)\n",
    "\n",
    "    return predicted\n",
    "\n",
    "# evaluate('Wh', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helper to print the amount of time passed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target, input: (batch, seq_len),\n",
    "def train(inp, target, mask):\n",
    "    hidden = decoder.init_hidden(batch_size)\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    seq_len = inp.size()[-1]\n",
    "    # output:(batch, seq_len, out_size),\n",
    "    # hidden: (num_layers * num_directions, batch, hidden_size)\n",
    "    output, hidden = decoder(inp, hidden)\n",
    "    loss_vec = criterion(output.view(-1, output.size()[-1]), target.view(-1)) # (batch*sesq_len)\n",
    "    loss = (torch.mul(mask.view(-1), loss_vec)).mean()\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] #/ chunk_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the training parameters, instantiate the model, and start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 8s (100 0%) 2.9124]\n",
      "\u0002I'm going ton what th  \n",
      "\n",
      "[0m 17s (200 0%) 5.6798]\n",
      "\u0002I'm going to de são?\u0003  \n",
      "\n",
      "[0m 26s (300 0%) 2.5667]\n",
      "\u0002I'm going tom onisiend \n",
      "\n",
      "[0m 35s (400 0%) 2.3862]\n",
      "\u0002I'm going to soure lil \n",
      "\n",
      "[0m 43s (500 0%) 2.4763]\n",
      "\u0002I'm going to deg tasen \n",
      "\n",
      "[0m 52s (600 0%) 3.6732]\n",
      "\u0002I'm going tolde, hay m \n",
      "\n",
      "[1m 1s (700 0%) 2.7497]\n",
      "\u0002I'm going to firida le \n",
      "\n",
      "[1m 10s (800 0%) 2.9543]\n",
      "\u0002I'm going to tos Tom m \n",
      "\n",
      "[1m 19s (900 0%) 2.3294]\n",
      "\u0002I'm going to tat-you m \n",
      "\n",
      "[1m 28s (1000 0%) 3.3042]\n",
      "\u0002I'm going toht bor he  \n",
      "\n",
      "[1m 36s (1100 0%) 2.4485]\n",
      "\u0002I'm going to, ve lete  \n",
      "\n",
      "[1m 45s (1200 0%) 2.4776]\n",
      "\u0002I'm going to Tom trie. \n",
      "\n",
      "[1m 54s (1300 0%) 2.5635]\n",
      "\u0002I'm going to era kaly. \n",
      "\n",
      "[2m 3s (1400 0%) 2.6151]\n",
      "\u0002I'm going to de de Ges \n",
      "\n",
      "[2m 12s (1500 0%) 2.4133]\n",
      "\u0002I'm going to onu but n \n",
      "\n",
      "[2m 20s (1600 0%) 2.3665]\n",
      "\u0002I'm going to thabow th \n",
      "\n",
      "[2m 29s (1700 0%) 2.6089]\n",
      "\u0002I'm going to felletrer \n",
      "\n",
      "[2m 39s (1800 0%) 2.0596]\n",
      "\u0002I'm going to.\u0003 Tom in  \n",
      "\n",
      "[2m 48s (1900 0%) 2.2536]\n",
      "\u0002I'm going to de de de  \n",
      "\n",
      "[2m 57s (2000 0%) 2.2996]\n",
      "\u0002I'm going to doment to \n",
      "\n",
      "[3m 10s (2100 0%) 2.7699]\n",
      "\u0002I'm going to de magy t \n",
      "\n",
      "[3m 19s (2200 0%) 1.7377]\n",
      "\u0002I'm going to mor du as \n",
      "\n",
      "[3m 28s (2300 0%) 2.5178]\n",
      "\u0002I'm going to Ben that  \n",
      "\n",
      "[3m 37s (2400 0%) 2.4403]\n",
      "\u0002I'm going to tabla vit \n",
      "\n",
      "[3m 46s (2500 0%) 2.5578]\n",
      "\u0002I'm going to don do th \n",
      "\n",
      "[3m 54s (2600 0%) 2.3682]\n",
      "\u0002I'm going to beggan.\u0003. \n",
      "\n",
      "[4m 3s (2700 0%) 2.5163]\n",
      "\u0002I'm going to do the wi \n",
      "\n",
      "[4m 12s (2800 0%) 2.3281]\n",
      "\u0002I'm going to tihong on \n",
      "\n",
      "[4m 21s (2900 0%) 3.5254]\n",
      "\u0002I'm going to do eore.\u0003 \n",
      "\n",
      "[4m 30s (3000 0%) 2.4989]\n",
      "\u0002I'm going to kiaten To \n",
      "\n",
      "[4m 39s (3100 0%) 2.3714]\n",
      "\u0002I'm going to do to to  \n",
      "\n",
      "[4m 47s (3200 0%) 2.4106]\n",
      "\u0002I'm going to by bout.\u0003 \n",
      "\n",
      "[4m 57s (3300 0%) 2.1496]\n",
      "\u0002I'm going to kun the T \n",
      "\n",
      "[5m 6s (3400 0%) 2.4914]\n",
      "\u0002I'm going to a qui tem \n",
      "\n",
      "[5m 15s (3500 0%) 2.4929]\n",
      "\u0002I'm going to the toran \n",
      "\n",
      "[5m 24s (3600 0%) 2.4153]\n",
      "\u0002I'm going to ellos sop \n",
      "\n",
      "[5m 33s (3700 0%) 2.4209]\n",
      "\u0002I'm going to hutto do  \n",
      "\n",
      "[5m 42s (3800 0%) 2.5280]\n",
      "\u0002I'm going to more do y \n",
      "\n",
      "[5m 51s (3900 0%) 2.3481]\n",
      "\u0002I'm going told a gous  \n",
      "\n",
      "[6m 0s (4000 0%) 2.5845]\n",
      "\u0002I'm going to what hod  \n",
      "\n",
      "[6m 15s (4100 0%) 2.4305]\n",
      "\u0002I'm going to she woull \n",
      "\n",
      "[6m 24s (4200 0%) 1.9315]\n",
      "\u0002I'm going to no thiss. \n",
      "\n",
      "[6m 33s (4300 0%) 5.8203]\n",
      "\u0002I'm going to tu thou t \n",
      "\n",
      "[6m 42s (4400 0%) 2.8251]\n",
      "\u0002I'm going to thy you'd \n",
      "\n",
      "[6m 50s (4500 0%) 2.6056]\n",
      "\u0002I'm going to grest a k \n",
      "\n",
      "[6m 59s (4600 0%) 2.4997]\n",
      "\u0002I'm going to ady to me \n",
      "\n",
      "[7m 8s (4700 0%) 2.3386]\n",
      "\u0002I'm going to briscel a \n",
      "\n",
      "[7m 17s (4800 0%) 2.4660]\n",
      "\u0002I'm going to kon the o \n",
      "\n",
      "[7m 26s (4900 0%) 2.3656]\n",
      "\u0002I'm going to the woomm \n",
      "\n",
      "[7m 35s (5000 0%) 2.3938]\n",
      "\u0002I'm going to trambilie \n",
      "\n",
      "[7m 44s (5100 0%) 2.3759]\n",
      "\u0002I'm going to he imortr \n",
      "\n",
      "[7m 52s (5200 0%) 2.2504]\n",
      "\u0002I'm going to do hen'h  \n",
      "\n",
      "[8m 2s (5300 0%) 2.3367]\n",
      "\u0002I'm going to limgente  \n",
      "\n",
      "[8m 11s (5400 0%) 2.4538]\n",
      "\u0002I'm going to eltie dan \n",
      "\n",
      "[8m 20s (5500 0%) 2.4144]\n",
      "\u0002I'm going to they woh  \n",
      "\n",
      "[8m 29s (5600 0%) 2.6456]\n",
      "\u0002I'm going to be far.\u0003  \n",
      "\n",
      "[8m 38s (5700 0%) 2.5816]\n",
      "\u0002I'm going to genwan de \n",
      "\n",
      "[8m 47s (5800 0%) 2.4664]\n",
      "\u0002I'm going to bey.\u0003 Fev \n",
      "\n",
      "[8m 56s (5900 0%) 2.2344]\n",
      "\u0002I'm going to bilen ged \n",
      "\n",
      "[9m 5s (6000 0%) 2.4646]\n",
      "\u0002I'm going to i safit?\u0003 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "n_epochs = 2*file_len//batch_size\n",
    "print_every = 100\n",
    "plot_every = 100\n",
    "save_every = 2000\n",
    "hidden_size = 512\n",
    "n_layers = 1\n",
    "batch_size=64\n",
    "lr = 0.005\n",
    "\n",
    "decoder = cuda_if_available(RNN(n_characters, hidden_size, n_characters, n_layers))\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss(reduce=False)\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(*random_training_set())       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "        print(evaluate(\"I'm going to\", 10), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0\n",
    "        \n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.cpu().state_dict(), 'mytraining_new.pt')\n",
    "        decoder = cuda_if_available(decoder)\n",
    "        with open('losses_new.npy', 'w') as outfile:\n",
    "            json.dump(all_losses, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Training Losses\n",
    "\n",
    "Plotting the historical loss from all_losses shows the network learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0628cb2e10>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3AVBEJIQUe6CIAhJyP8D9DfgmuF6LVgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f06319387b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating at different \"temperatures\"\n",
    "\n",
    "In the `evaluate` function above, every time a prediction is made the outputs are divided by the \"temperature\" argument passed. Using a higher number makes all actions more equally likely, and thus gives us \"more random\" outputs. Using a lower value (less than 1) makes high probabilities contribute more. As we turn the temperature towards zero we are choosing only the most likely outputs.\n",
    "\n",
    "We can see the effects of this by adjusting the `temperature` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Th heok couns him.\n",
      "\n",
      "KING EDWARD IV:\n",
      "And fear allow is it he do soul, if who the min all his boldle eeve\n",
      "Wousen me mady; good queie: the call extive your his?\n",
      "\n",
      "QUEEN CAPLaLA:\n",
      "And son hell plesend other r\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Th', 200, temperature=0.8))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
